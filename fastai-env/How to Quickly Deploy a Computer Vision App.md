이 글에서는 저는 여러분에게 컴퓨터 비전 분류 모델을 사용하여 개념에서 배포까지 옮겨가는 방법을 소개하려고 합니다. fastai와 함께 여러분은 빠르게 최신 딥러닝 모델을 빌드하고 훈련할 수 있습니다. 그런 다음, Render(*Deployment Platform*)는 앱을 호스팅하고 배포하는 것을 쉽게 만들어줍니다.

우리는 피부병변 영상을 분류할 수 있는 모델을 빌드하고 배포하는 것을 하나하나씩 배워볼 것입니다. 우리가 이를 마쳤을 때 사용자들이 이미지를 업로드할 수 있고, 모델이 그들의 피부병변을 분류할 것입니다.

저는 이와 비슷한 NLP 관련 글도 계획중에 있습니다. [저를 구독](https://medium.com/@jeffhale)해서 놓치지 말길 바랍니다.


## 고지서

**건강/법률** : 이 프로젝트는 오직 논증을 목적으로 합나다. 여러분이 만약 피부병을 앓고 있다고 생각한다면, 전문적인 피부 치료를 받길 바랍니다. 저는 피부 치료 전문가가 아니니까요.

**기술적인 것** : 이 예제는 백만 단위의 조회수를 기록하는 대규모의 웹사이트를 대상으로 한 것이 아닙니다. 여러분이 이러한 문제를 가지고 있다면, 음, 뭐 좋은 문제라고 할 수 있겠군요.
저는 이 구조가 작동하지 않을거라고 말씀드리는 게 아닙니다. Render는 뒤에서 도커와 쿠버네티스를 이용하여 가능한 성능저하 없이 스케일링을 합니다.

좋습니다. 이제 실전으로 가시죠!

![Training set images]()

피부암은 암 종류 중에서 가장 흔한 병입니다. 피부 병변을 분류하는 수 많은 앱들이 개발되어 왔습니다. 여러분의 의심스러운 피부 일부를 사진으로 업로드하면 피부과 의사와 상담해야 하는지 알 수 있습니다. 제 생각에는 제 스스로 만들어보기에 좋은 프로젝트라고 생각했습니다.

계획은 이렇습니다.

1. 데이터를 찾는다.
2. 모델을 제작하고 훈련한다.
3. 모델을 배포한다.
4. 모델 성능을 향상시킨다.

이제 이 계획에 살을 붙여보겠습니다.


## 단계

1. 데이터를 찾습니다. 저는 피부 점에 대한 데이터셋을 어디선가 봤던 걸 기억합니다. 아마 UCI나 data.world, Kaggle일겁니다. 검색하고 찾아보겠습니다.

2. 모델을 제작하고 훈련합니다. 저는 현재 fast.ai의 딥러닝 MOOC를 수강하고 있습니다. 그래서 fastai와 고수준의 PyTorch 라이브러리로 제 모델을 학습하는데 사용하도록 할겁니다. fastai는 여러분에게 수 많은 최신 기술과 컴퓨터 비전 업무에서 편리함을 제공하는 API를 적용할 수 있도록 만들어줍니다. 저는 데이터 증강과 전이학습, 학습률 조정을 사용할 예정입니다. 또한 클라우드 상의 GPU를 사용한 쥬피터 노트북으로 훈련하겠습니다.

3. 모델을 배포합니다. fastai의 문서는 [Render](https://render.com/)를 통해 월 5$에 모델을 배포할 수 있는 가이드를 담고 있습니다. 우리는 이를 이용하며 중간중간 설명하도록 하겠습니다.

4. 우리가 모델을 배포한 뒤에, 우리는 이전 단계로 돌아가 모델의 성능을 개선하도록 하겠습니다.

그럼 시작해보겠습니다.


## 데이터 사냥

저는 하버드 연구진들이 모아놓은 10,015장의 피부질환 이미지를 [여기에서](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T) 찾았습니다.

매년 몇 가지 데이터 양상를 다루는 [ISIC competition](https://www.isic-archive.com/#!/topWithHeader/tightContentTop/challenges)이 있습니다. 다른 필터를 가진 이미지는 [여기에서](https://www.isic-archive.com/#!/topWithHeader/onlyHeaderTop/gallery) 보실 수 있습니다.

![Images from ISIC]()

저는 피부병변을 분류하기 위해 같은 데이터 셋을 Kaggle에서 찾았습니다. Kaggle notebook에서 한번 확인해보겠습니다. 그러나 하드디스크의 용량과 공유된 도커 컨테이너 메모리의 한계가 우리를 옭아매고 있기 때문에, 우리는 Colab으로 옮겨야 할 것 같습니 두 가지 무과금 선택지에 대한 [제 글](https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=friends_link&sk=7eb54f51566742d937b8d41adaee1bb9)을 참고하세요.

피부병변 이미지는 두 개의 압축폴더에 압축되어 있습니다. 저는 Kaggle에서 두 개의 데이터셋 압축파일을 하나로 합칠 수 있는 방법을 찾지 못했습니다. 저는 누군가가 데이터를 로드하기 위해 만들어놓은 커스텀 데이터뭉치를 찾았지만, 너무 까다롭고, 이 연습에서는 진행하지 않을 것 입니다.

저는 그냥 데이터를 다운로드받고 압축해서 다시 업로드해야겠다고 생각했습니다. 그러나 데이터를 업로드하는 일은 무지막지하게 시간이 오래 걸렸습니다. 결국 업로드를 해냈고, 여러분은 [여기에서](https://www.kaggle.com/discdiver/mnist1000-with-one-image-folder) 한 폴더로 데이터를 사용할 수 있게 되었습니다.


## 데이터 탐색

HAM10000_metadata.csv라는 메타데이터가 있는 파일이 하나 있습니다. 아주 편리한 녀석입니다. 여기 내용물과 처음의 제 견해를 적어보겠습니다.

lesion_id : 각 병변마다 한 개씩 가지는 id. 각 병변은 둘 이상의 이미지를 가질 수 있습니다.

image_id : 각 병변마다 가지고 있는 이미지의 목록. sans.jpg와 같은 파일이름입니다.

dx : 진단서. 7종류가 있으며 추측컨데 DV(Digital Video)입니다.

dx_type : 진단서가 어떻게 만들어졌는지.

age : 나이. 57개의 값이 누락되어 있습니다. 이를 처리할 때 다른 전략을 시도해볼 수 있습니다.

sex : 성별. 3가지 값이 있습니다.

localization : 몸에서의 위치. 15가지 값이 있습니다.

독특한 사례보다 더 많은 이미지들이 있습니다. 저는 [여기에서](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6091241/) 같은 이미지가 다른 배율에서 포함되기 때문이라는 것을 알아냈습니다. 이것은 사실상의 데이터 증강입니다.


## 첫 의문점들

결과 변수에 대해 얼마나 많은 분류 라벨이 존재할까요? 7개입니다.(멜라닌세포 모반, 흑색종, 양성 각화증, 기저세포암, 광선 각화증, 혈관병변, 피부섬유종) 흑색종은 피부암 중 가장 위험한 종류라는 것을 알아두시기 바랍니다. 여러분은 또한 기저세포암이 가장 빈번한 피부암 종류라는 것과 광선 각화증이 잠재적인 전암(**역자 주 : 고빈도로 암이 되기 쉬운 상태**)으로 여겨지는 것을 알아둬야 합니다.

어떤 이미지도 한 개 이상의 종류로 분류될 것 같아보이지 않고, 우리는 다분류 문제와 직면했지만, 다중 라벨의 문제는 아닙니다.

이 데이터가 균형이 맞지 않나요? 그렇습니다. 67%가 멜라닌세포 모반을 의미하는 nv 종류입니다.

![데이터 분포]()

우리는 불균형한 분류에 대한 보고서 측정지표에 주의할 필요가 있습니다. 예를 들어 정확도는 매우 통찰력있는 측정지표가 되지 않을 것 입니다. 그러나 fast.ai의 [Jeremy Howard](https://www.youtube.com/watch?v=Egp4Zajhzog&feature=youtu.be&t=4200)에 따르면, 우리는 딥러닝 모델을 학습할 때 불균형한 데이터셋에 대해 걱정할 필요가 없다고 합니다. 네트워크가 그 분류를 알아낼 것이기 때문입니다.


## 데이터 준비

우리는 우리가 자주 사용하는 라이브러리를 임포트하고 딥러닝을 위한 몇 가지를 구성할 것입니다. Kaggle은 최신의 PyTorch와 fastai 라이브러리를 지원하지 않기 때문에, 우리는 인터넷을 켜고 pip를 통해 설치하도록 하겠습니다.

가지고 있는 GPU를 켜보겠습니다. 우리는 우리가 생각하고 있는 자원을 가지고 있는지 확인하기 위해, 다시금 사용하기 위해, 자신의 하드웨어와 소프트웨어를 목록화할 것입니다.

저는 합쳐놓은 데이터파일을 업로드하는데 지쳐서, Colab으로 전환하기로 했습니다. 저는 Kaggle에 있는 데이터셋을 Colab으로 가져올 수 있는 API가 있다는 것을 깨달았습니다. 그 때 저는 이미지 파일을 합치고 구글 드라이브 폴더에 저장하고 있었습니다. 좀 번거로운 일이었지만, 현재 데이터가 제 드라이브 폴더에 있기 때문에 꽤나 편리해졌습니다. 여기에 [제 Colab notebook](https://colab.research.google.com/drive/1y1hZS-nmcA3SBH7tF4uttAGMwNS3z9jx)이 있습니다.


## 모델 제작

저는 fastai v.1.50.0버전, torch v1.0.1.post2버전, torchvision v0.2.2.post3버전을 사용하고 있습니다.

먼저, 데이터의 일부분을 빠른 훈련에 사용해서 모든 것을 작동시켜보도록 합시다. 우리가 설령 옳은 길을 가고 있는지 확인하고 싶을 때 훈련을 기다리는 것에 많은 시간을 쏟아부을 필요는 없습니다. 우리는 훈련과 검증 셋을 위해서 10,015장 대신 1000장의 무작위 이미지 샘플로 시작하겠습니다. 일단 문제가 해결 된다면, 나중에 전체 데이터 세트를 사용할 수 있습니다.
